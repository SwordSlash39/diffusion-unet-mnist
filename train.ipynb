{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a87d5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1. Define a transform to convert images to tensors\n",
    "# Transform to -1, 1\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(32),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "    transforms.RandomRotation(10),\n",
    "])\n",
    "\n",
    "# 2. Download and load the training data\n",
    "ds = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# 4. Use a DataLoader to iterate through the data in batches\n",
    "loader = DataLoader(ds, batch_size=256, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5f3aae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "class DownsampleBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.downsample = nn.MaxPool2d(\n",
    "            kernel_size=2,\n",
    "            stride=2,\n",
    "            padding=0\n",
    "        )\n",
    "        self.expand_block = nn.Sequential(\n",
    "            nn.GroupNorm(1, channels),\n",
    "            nn.Conv2d(\n",
    "                in_channels=channels,\n",
    "                out_channels=channels * 2,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1\n",
    "            ), # Expand it up\n",
    "            nn.SiLU(),\n",
    "            # Few depth wise convs\n",
    "            nn.Conv2d(\n",
    "                in_channels=channels * 2,\n",
    "                out_channels=channels * 2,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "                groups=channels * 2\n",
    "            ),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=channels * 2,\n",
    "                out_channels=channels * 2,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "                groups=channels * 2\n",
    "            ),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (B, channels, H, W)\n",
    "        x = self.downsample(x)\n",
    "        return self.expand_block(x)\n",
    "\n",
    "class UpsampleResBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.ConvTranspose2d(\n",
    "            in_channels=channels,\n",
    "            out_channels=channels // 2,\n",
    "            kernel_size=2,\n",
    "            stride=2,\n",
    "            padding=0\n",
    "        )\n",
    "        \n",
    "        # Note here we will get another concat channel so we have channels\n",
    "        self.concat_block = nn.Sequential(\n",
    "            nn.GroupNorm(1, channels),\n",
    "            nn.Conv2d(\n",
    "                in_channels=channels,\n",
    "                out_channels=channels // 2,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1\n",
    "            ), \n",
    "            nn.SiLU(),\n",
    "            # Few depth wise convs\n",
    "            nn.Conv2d(\n",
    "                in_channels=channels // 2,\n",
    "                out_channels=channels // 2,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "                groups=channels // 2\n",
    "            ),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=channels // 2,\n",
    "                out_channels=channels // 2,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "                groups=channels // 2\n",
    "            ),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "    def forward(self, x, res_channel):\n",
    "        x = self.upsample(x) # (B, channels // 2, H*2, W*2)\n",
    "        # Concat res channel\n",
    "        x = torch.cat([x, res_channel], dim=1) # (B, channels, H*2, W*2)\n",
    "        return self.concat_block(x)\n",
    "\n",
    "class Diffusion(nn.Module):\n",
    "    def __init__(self, in_channels, latent_channels, num_classes):\n",
    "        \"\"\"\n",
    "        Model will expand from in_channels x H x W to latent_dim x H x W\n",
    "        Inputs here are meant for 28x28\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.latent_channels = latent_channels\n",
    "        \n",
    "        self.class_dict = nn.Embedding(num_classes, latent_channels*2) # Add a tunable gamma and beta to edit each latent_dim to embed class information\n",
    "        self.time_fn = nn.Sequential(\n",
    "            nn.Linear(1, latent_channels * 2),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(latent_channels * 2, latent_channels * 2), # Predict sin waves, so each value is a coefficient used in sin(kT)\n",
    "        )\n",
    "        self.time_editor = nn.Linear(latent_channels * 2, latent_channels * 2) # Used AFTER sin to project values properly\n",
    "        \n",
    "        self.latent_expansion = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=latent_channels,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1\n",
    "            ),\n",
    "            nn.SiLU(),\n",
    "            \n",
    "            # Few depth wise conv\n",
    "            nn.Conv2d(\n",
    "                in_channels=latent_channels,\n",
    "                out_channels=latent_channels,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "                groups=latent_channels\n",
    "            ),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=latent_channels,\n",
    "                out_channels=latent_channels,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "                groups=latent_channels\n",
    "            ),\n",
    "            nn.SiLU(),\n",
    "        ) # (LC, 32, 32) \n",
    "        \n",
    "        self.block1 = DownsampleBlock(latent_channels) # (LC * 2, 16, 16)\n",
    "        self.block2 = DownsampleBlock(latent_channels * 2) # (LC * 4, 8, 8)\n",
    "        self.block3 = DownsampleBlock(latent_channels * 4) # (LC * 8, 4, 4)\n",
    "        self.block4 = DownsampleBlock(latent_channels * 8) # (LC * 16, 2, 2)\n",
    "        \n",
    "        self.block5_3 = UpsampleResBlock(latent_channels * 16) # 4_3 means 3 is the residual to 4\n",
    "        self.block6_2 = UpsampleResBlock(latent_channels * 8) # Note block4 is not used (cant residue yourself)\n",
    "        self.block7_1 = UpsampleResBlock(latent_channels * 4) # (LC * 2, 32, 32)\n",
    "        \n",
    "        # This block uses our latent expansion\n",
    "        self.block8_latents = UpsampleResBlock(latent_channels * 2) # (LC, 32, 32)\n",
    "        \n",
    "        # Get x back to in_channels\n",
    "        self.output_head = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=latent_channels,\n",
    "                out_channels=in_channels,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                padding=0\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, target_class, t):\n",
    "        # x: (B, C, 28, 28)\n",
    "        # target_class: (B,)\n",
    "        # t (B,)\n",
    "        t = t.unsqueeze(1)\n",
    "        B = target_class.shape[0]\n",
    "        \n",
    "        class_modifier = self.class_dict(target_class) # (B, LC * 2)\n",
    "        time_modifier = self.time_editor(torch.sin(self.time_fn(t) * t))\n",
    "        modifier = class_modifier + time_modifier\n",
    "        x = self.latent_expansion(x) # (B, LC, 32, 32)\n",
    "        \n",
    "        # Get gamma and beta\n",
    "        modifier = modifier.view(B, self.latent_channels, 2)\n",
    "        gamma, beta = torch.unbind(modifier, dim=-1) # (B, LC) each\n",
    "        gamma = gamma.view(B, self.latent_channels, 1, 1)\n",
    "        beta = beta.view(B, self.latent_channels, 1, 1) \n",
    "        \n",
    "        # Transform x\n",
    "        x = (x * (1 + gamma)) + beta # (B, LC, 32, 32)\n",
    "        \n",
    "        # Run all blocks\n",
    "        b1 = self.block1(x)\n",
    "        b2 = self.block2(b1)\n",
    "        b3 = self.block3(b2) # (B, LC * 8, 4, 4)\n",
    "        b4 = self.block4(b3)\n",
    "        b5 = self.block5_3(b4, b3)\n",
    "        b6 = self.block6_2(b5, b2)\n",
    "        b7 = self.block7_1(b6, b1)\n",
    "        b8 = self.block8_latents(b7, x) # (B, LC, 32, 32)\n",
    "        \n",
    "        # Get output\n",
    "        out = self.output_head(b8)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c72bc777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "class EMA:\n",
    "    def __init__(self, model, decay=0.9997):\n",
    "        self.ema_model = copy.deepcopy(model)\n",
    "        self.ema_model.eval()\n",
    "        self.decay = decay\n",
    "        # Stop gradients for the EMA model\n",
    "        for param in self.ema_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, model):\n",
    "        # model is the one being trained\n",
    "        for ema_param, current_param in zip(self.ema_model.parameters(), model.parameters()):\n",
    "            ema_param.data.mul_(self.decay).add_(current_param.data, alpha=1 - self.decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0134fa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_optimizers(model, weight_decay, learning_rate):\n",
    "    # 1. Create empty lists\n",
    "    decay_params = []\n",
    "    nodecay_params = []\n",
    "    \n",
    "    # 2. Iterate over named parameters\n",
    "    for pn, p in model.named_parameters():\n",
    "        if p.requires_grad:\n",
    "            \n",
    "            # CHECK 1: Dimensions\n",
    "            # - Weights are usually >= 2D\n",
    "            # - Biases and Norms are 1D\n",
    "            is_bias_or_norm = p.dim() < 2\n",
    "            \n",
    "            # CHECK 2: Explicit Names to EXCLUDE from decay\n",
    "            # If 'pos_embedding' is in the name, force it to no_decay\n",
    "            no_decay_names = [\n",
    "                'class_dict'\n",
    "            ]\n",
    "\n",
    "            # Logic: If it's big (2D+) AND NOT an embedding, decay it.\n",
    "            if is_bias_or_norm or any(nd in pn for nd in no_decay_names):\n",
    "                nodecay_params.append(p)\n",
    "            else:\n",
    "                decay_params.append(p)\n",
    "\n",
    "    optim_groups = [\n",
    "        {'params': decay_params, 'weight_decay': weight_decay},\n",
    "        {'params': nodecay_params, 'weight_decay': 0.0}\n",
    "    ]\n",
    "    \n",
    "    return torch.optim.AdamW(optim_groups, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fae8430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_noise(x):\n",
    "    B = x.shape[0]\n",
    "    noise_ratio = torch.rand((B, 1, 1, 1), dtype=torch.float32)\n",
    "    \n",
    "    noise = torch.randn_like(x)\n",
    "    noised_x = torch.sqrt(1 - noise_ratio) * x + torch.sqrt(noise_ratio) * noise\n",
    "    \n",
    "    return noised_x, noise, noise_ratio.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93766b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4f232cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15422785"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Diffusion(1, 64, 10).to(device)\n",
    "ema_model = EMA(model)\n",
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e11b7e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = configure_optimizers(model, 0, 1e-3)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5942fb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50\n",
      "Loss: 0.2935\n",
      "Epoch: 100\n",
      "Loss: 0.1276\n",
      "Epoch: 150\n",
      "Loss: 0.1068\n",
      "Epoch: 200\n",
      "Loss: 0.0856\n",
      "Epoch: 250\n",
      "Loss: 0.0892\n",
      "Epoch: 300\n",
      "Loss: 0.0689\n",
      "Epoch: 350\n",
      "Loss: 0.0678\n",
      "Epoch: 400\n",
      "Loss: 0.0539\n",
      "Epoch: 450\n",
      "Loss: 0.0683\n",
      "Epoch: 500\n",
      "Loss: 0.0571\n",
      "Epoch: 550\n",
      "Loss: 0.0660\n",
      "Epoch: 600\n",
      "Loss: 0.0510\n",
      "Epoch: 650\n",
      "Loss: 0.0523\n",
      "Epoch: 700\n",
      "Loss: 0.0478\n",
      "Epoch: 750\n",
      "Loss: 0.0498\n",
      "Epoch: 800\n",
      "Loss: 0.0498\n",
      "Epoch: 850\n",
      "Loss: 0.0461\n",
      "Epoch: 900\n",
      "Loss: 0.0521\n",
      "Epoch: 950\n",
      "Loss: 0.0484\n",
      "Epoch: 1000\n",
      "Loss: 0.0464\n",
      "Epoch: 1050\n",
      "Loss: 0.0443\n",
      "Epoch: 1100\n",
      "Loss: 0.0455\n",
      "Epoch: 1150\n",
      "Loss: 0.0510\n",
      "Epoch: 1200\n",
      "Loss: 0.0434\n",
      "Epoch: 1250\n",
      "Loss: 0.0488\n",
      "Epoch: 1300\n",
      "Loss: 0.0413\n",
      "Epoch: 1350\n",
      "Loss: 0.0414\n",
      "Epoch: 1400\n",
      "Loss: 0.0408\n",
      "Epoch: 1450\n",
      "Loss: 0.0461\n",
      "Epoch: 1500\n",
      "Loss: 0.0356\n",
      "Epoch: 1550\n",
      "Loss: 0.0434\n",
      "Epoch: 1600\n",
      "Loss: 0.0443\n",
      "Epoch: 1650\n",
      "Loss: 0.0388\n",
      "Epoch: 1700\n",
      "Loss: 0.0346\n",
      "Epoch: 1750\n",
      "Loss: 0.0409\n",
      "Epoch: 1800\n",
      "Loss: 0.0398\n",
      "Epoch: 1850\n",
      "Loss: 0.0358\n",
      "Epoch: 1900\n",
      "Loss: 0.0386\n",
      "Epoch: 1950\n",
      "Loss: 0.0359\n",
      "Epoch: 2000\n",
      "Loss: 0.0426\n",
      "Epoch: 2050\n",
      "Loss: 0.0423\n",
      "Epoch: 2100\n",
      "Loss: 0.0404\n",
      "Epoch: 2150\n",
      "Loss: 0.0374\n",
      "Epoch: 2200\n",
      "Loss: 0.0363\n",
      "Epoch: 2250\n",
      "Loss: 0.0363\n",
      "Epoch: 2300\n",
      "Loss: 0.0358\n",
      "Epoch: 2350\n",
      "Loss: 0.0364\n",
      "Epoch: 2400\n",
      "Loss: 0.0367\n",
      "Epoch: 2450\n",
      "Loss: 0.0400\n",
      "Epoch: 2500\n",
      "Loss: 0.0318\n",
      "Epoch: 2550\n",
      "Loss: 0.0350\n",
      "Epoch: 2600\n",
      "Loss: 0.0345\n",
      "Epoch: 2650\n",
      "Loss: 0.0349\n",
      "Epoch: 2700\n",
      "Loss: 0.0377\n",
      "Epoch: 2750\n",
      "Loss: 0.0332\n",
      "Epoch: 2800\n",
      "Loss: 0.0366\n",
      "Epoch: 2850\n",
      "Loss: 0.0317\n",
      "Epoch: 2900\n",
      "Loss: 0.0364\n",
      "Epoch: 2950\n",
      "Loss: 0.0391\n",
      "Epoch: 3000\n",
      "Loss: 0.0361\n",
      "Epoch: 3050\n",
      "Loss: 0.0354\n",
      "Epoch: 3100\n",
      "Loss: 0.0352\n",
      "Epoch: 3150\n",
      "Loss: 0.0334\n",
      "Epoch: 3200\n",
      "Loss: 0.0348\n",
      "Epoch: 3250\n",
      "Loss: 0.0303\n",
      "Epoch: 3300\n",
      "Loss: 0.0328\n",
      "Epoch: 3350\n",
      "Loss: 0.0304\n",
      "Epoch: 3400\n",
      "Loss: 0.0342\n",
      "Epoch: 3450\n",
      "Loss: 0.0326\n",
      "Epoch: 3500\n",
      "Loss: 0.0348\n",
      "Epoch: 3550\n",
      "Loss: 0.0307\n",
      "Epoch: 3600\n",
      "Loss: 0.0326\n",
      "Epoch: 3650\n",
      "Loss: 0.0320\n",
      "Epoch: 3700\n",
      "Loss: 0.0332\n",
      "Epoch: 3750\n",
      "Loss: 0.0335\n",
      "Epoch: 3800\n",
      "Loss: 0.0343\n",
      "Epoch: 3850\n",
      "Loss: 0.0345\n",
      "Epoch: 3900\n",
      "Loss: 0.0313\n",
      "Epoch: 3950\n",
      "Loss: 0.0378\n",
      "Epoch: 4000\n",
      "Loss: 0.0339\n",
      "Epoch: 4050\n",
      "Loss: 0.0338\n",
      "Epoch: 4100\n",
      "Loss: 0.0335\n",
      "Epoch: 4150\n",
      "Loss: 0.0315\n",
      "Epoch: 4200\n",
      "Loss: 0.0303\n",
      "Epoch: 4250\n",
      "Loss: 0.0311\n",
      "Epoch: 4300\n",
      "Loss: 0.0308\n",
      "Epoch: 4350\n",
      "Loss: 0.0340\n",
      "Epoch: 4400\n",
      "Loss: 0.0298\n",
      "Epoch: 4450\n",
      "Loss: 0.0330\n",
      "Epoch: 4500\n",
      "Loss: 0.0306\n",
      "Epoch: 4550\n",
      "Loss: 0.0312\n",
      "Epoch: 4600\n",
      "Loss: 0.0311\n",
      "Epoch: 4650\n",
      "Loss: 0.0337\n",
      "Epoch: 4700\n",
      "Loss: 0.0315\n",
      "Epoch: 4750\n",
      "Loss: 0.0337\n",
      "Epoch: 4800\n",
      "Loss: 0.0340\n",
      "Epoch: 4850\n",
      "Loss: 0.0290\n",
      "Epoch: 4900\n",
      "Loss: 0.0292\n",
      "Epoch: 4950\n",
      "Loss: 0.0307\n",
      "Epoch: 5000\n",
      "Loss: 0.0325\n",
      "Epoch: 5050\n",
      "Loss: 0.0319\n",
      "Epoch: 5100\n",
      "Loss: 0.0352\n",
      "Epoch: 5150\n",
      "Loss: 0.0343\n",
      "Epoch: 5200\n",
      "Loss: 0.0322\n",
      "Epoch: 5250\n",
      "Loss: 0.0314\n",
      "Epoch: 5300\n",
      "Loss: 0.0307\n",
      "Epoch: 5350\n",
      "Loss: 0.0356\n",
      "Epoch: 5400\n",
      "Loss: 0.0316\n",
      "Epoch: 5450\n",
      "Loss: 0.0341\n",
      "Epoch: 5500\n",
      "Loss: 0.0304\n",
      "Epoch: 5550\n",
      "Loss: 0.0299\n",
      "Epoch: 5600\n",
      "Loss: 0.0309\n",
      "Epoch: 5650\n",
      "Loss: 0.0327\n",
      "Epoch: 5700\n",
      "Loss: 0.0281\n",
      "Epoch: 5750\n",
      "Loss: 0.0307\n",
      "Epoch: 5800\n",
      "Loss: 0.0330\n",
      "Epoch: 5850\n",
      "Loss: 0.0306\n",
      "Epoch: 5900\n",
      "Loss: 0.0306\n",
      "Epoch: 5950\n",
      "Loss: 0.0289\n",
      "Epoch: 6000\n",
      "Loss: 0.0291\n",
      "Epoch: 6050\n",
      "Loss: 0.0292\n",
      "Epoch: 6100\n",
      "Loss: 0.0299\n",
      "Epoch: 6150\n",
      "Loss: 0.0301\n",
      "Epoch: 6200\n",
      "Loss: 0.0280\n",
      "Epoch: 6250\n",
      "Loss: 0.0308\n",
      "Epoch: 6300\n",
      "Loss: 0.0320\n",
      "Epoch: 6350\n",
      "Loss: 0.0323\n",
      "Epoch: 6400\n",
      "Loss: 0.0300\n",
      "Epoch: 6450\n",
      "Loss: 0.0297\n",
      "Epoch: 6500\n",
      "Loss: 0.0280\n",
      "Epoch: 6550\n",
      "Loss: 0.0309\n",
      "Epoch: 6600\n",
      "Loss: 0.0276\n",
      "Epoch: 6650\n",
      "Loss: 0.0319\n",
      "Epoch: 6700\n",
      "Loss: 0.0306\n",
      "Epoch: 6750\n",
      "Loss: 0.0288\n",
      "Epoch: 6800\n",
      "Loss: 0.0301\n",
      "Epoch: 6850\n",
      "Loss: 0.0267\n",
      "Epoch: 6900\n",
      "Loss: 0.0274\n",
      "Epoch: 6950\n",
      "Loss: 0.0285\n",
      "Epoch: 7000\n",
      "Loss: 0.0300\n",
      "Epoch: 7050\n",
      "Loss: 0.0312\n",
      "Epoch: 7100\n",
      "Loss: 0.0307\n",
      "Epoch: 7150\n",
      "Loss: 0.0312\n",
      "Epoch: 7200\n",
      "Loss: 0.0311\n",
      "Epoch: 7250\n",
      "Loss: 0.0317\n",
      "Epoch: 7300\n",
      "Loss: 0.0282\n",
      "Epoch: 7350\n",
      "Loss: 0.0324\n",
      "Epoch: 7400\n",
      "Loss: 0.0276\n",
      "Epoch: 7450\n",
      "Loss: 0.0298\n",
      "Epoch: 7500\n",
      "Loss: 0.0301\n",
      "Epoch: 7550\n",
      "Loss: 0.0302\n",
      "Epoch: 7600\n",
      "Loss: 0.0300\n",
      "Epoch: 7650\n",
      "Loss: 0.0322\n",
      "Epoch: 7700\n",
      "Loss: 0.0303\n",
      "Epoch: 7750\n",
      "Loss: 0.0287\n",
      "Epoch: 7800\n",
      "Loss: 0.0303\n",
      "Epoch: 7850\n",
      "Loss: 0.0286\n",
      "Epoch: 7900\n",
      "Loss: 0.0300\n",
      "Epoch: 7950\n",
      "Loss: 0.0293\n",
      "Epoch: 8000\n",
      "Loss: 0.0298\n",
      "Epoch: 8050\n",
      "Loss: 0.0294\n",
      "Epoch: 8100\n",
      "Loss: 0.0294\n",
      "Epoch: 8150\n",
      "Loss: 0.0341\n",
      "Epoch: 8200\n",
      "Loss: 0.0305\n",
      "Epoch: 8250\n",
      "Loss: 0.0335\n",
      "Epoch: 8300\n",
      "Loss: 0.0335\n",
      "Epoch: 8350\n",
      "Loss: 0.0277\n",
      "Epoch: 8400\n",
      "Loss: 0.0262\n",
      "Epoch: 8450\n",
      "Loss: 0.0299\n",
      "Epoch: 8500\n",
      "Loss: 0.0306\n",
      "Epoch: 8550\n",
      "Loss: 0.0324\n",
      "Epoch: 8600\n",
      "Loss: 0.0274\n",
      "Epoch: 8650\n",
      "Loss: 0.0295\n",
      "Epoch: 8700\n",
      "Loss: 0.0289\n",
      "Epoch: 8750\n",
      "Loss: 0.0290\n",
      "Epoch: 8800\n",
      "Loss: 0.0315\n",
      "Epoch: 8850\n",
      "Loss: 0.0272\n",
      "Epoch: 8900\n",
      "Loss: 0.0325\n",
      "Epoch: 8950\n",
      "Loss: 0.0288\n",
      "Epoch: 9000\n",
      "Loss: 0.0290\n",
      "Epoch: 9050\n",
      "Loss: 0.0287\n",
      "Epoch: 9100\n",
      "Loss: 0.0308\n",
      "Epoch: 9150\n",
      "Loss: 0.0292\n",
      "Epoch: 9200\n",
      "Loss: 0.0331\n",
      "Epoch: 9250\n",
      "Loss: 0.0282\n",
      "Epoch: 9300\n",
      "Loss: 0.0289\n",
      "Epoch: 9350\n",
      "Loss: 0.0285\n",
      "Epoch: 9400\n",
      "Loss: 0.0301\n",
      "Epoch: 9450\n",
      "Loss: 0.0289\n",
      "Epoch: 9500\n",
      "Loss: 0.0278\n",
      "Epoch: 9550\n",
      "Loss: 0.0304\n",
      "Epoch: 9600\n",
      "Loss: 0.0306\n",
      "Epoch: 9650\n",
      "Loss: 0.0274\n",
      "Epoch: 9700\n",
      "Loss: 0.0302\n",
      "Epoch: 9750\n",
      "Loss: 0.0320\n",
      "Epoch: 9800\n",
      "Loss: 0.0294\n",
      "Epoch: 9850\n",
      "Loss: 0.0265\n",
      "Epoch: 9900\n",
      "Loss: 0.0283\n",
      "Epoch: 9950\n",
      "Loss: 0.0317\n",
      "Epoch: 10000\n",
      "Loss: 0.0299\n",
      "Epoch: 10050\n",
      "Loss: 0.0292\n",
      "Epoch: 10100\n",
      "Loss: 0.0276\n",
      "Epoch: 10150\n",
      "Loss: 0.0285\n",
      "Epoch: 10200\n",
      "Loss: 0.0295\n",
      "Epoch: 10250\n",
      "Loss: 0.0320\n",
      "Epoch: 10300\n",
      "Loss: 0.0317\n",
      "Epoch: 10350\n",
      "Loss: 0.0287\n",
      "Epoch: 10400\n",
      "Loss: 0.0273\n",
      "Epoch: 10450\n",
      "Loss: 0.0292\n",
      "Epoch: 10500\n",
      "Loss: 0.0288\n",
      "Epoch: 10550\n",
      "Loss: 0.0278\n",
      "Epoch: 10600\n",
      "Loss: 0.0270\n",
      "Epoch: 10650\n",
      "Loss: 0.0301\n",
      "Epoch: 10700\n",
      "Loss: 0.0289\n",
      "Epoch: 10750\n",
      "Loss: 0.0278\n",
      "Epoch: 10800\n",
      "Loss: 0.0284\n",
      "Epoch: 10850\n",
      "Loss: 0.0293\n",
      "Epoch: 10900\n",
      "Loss: 0.0274\n",
      "Epoch: 10950\n",
      "Loss: 0.0289\n",
      "Epoch: 11000\n",
      "Loss: 0.0310\n",
      "Epoch: 11050\n",
      "Loss: 0.0287\n",
      "Epoch: 11100\n",
      "Loss: 0.0270\n",
      "Epoch: 11150\n",
      "Loss: 0.0287\n",
      "Epoch: 11200\n",
      "Loss: 0.0296\n",
      "Epoch: 11250\n",
      "Loss: 0.0292\n",
      "Epoch: 11300\n",
      "Loss: 0.0284\n",
      "Epoch: 11350\n",
      "Loss: 0.0280\n",
      "Epoch: 11400\n",
      "Loss: 0.0283\n",
      "Epoch: 11450\n",
      "Loss: 0.0270\n",
      "Epoch: 11500\n",
      "Loss: 0.0281\n",
      "Epoch: 11550\n",
      "Loss: 0.0309\n",
      "Epoch: 11600\n",
      "Loss: 0.0273\n",
      "Epoch: 11650\n",
      "Loss: 0.0283\n",
      "Epoch: 11700\n",
      "Loss: 0.0290\n",
      "Epoch: 11750\n",
      "Loss: 0.0306\n",
      "Epoch: 11800\n",
      "Loss: 0.0279\n",
      "Epoch: 11850\n",
      "Loss: 0.0284\n",
      "Epoch: 11900\n",
      "Loss: 0.0284\n",
      "Epoch: 11950\n",
      "Loss: 0.0295\n",
      "Epoch: 12000\n",
      "Loss: 0.0258\n",
      "Epoch: 12050\n",
      "Loss: 0.0264\n",
      "Epoch: 12100\n",
      "Loss: 0.0260\n",
      "Epoch: 12150\n",
      "Loss: 0.0261\n",
      "Epoch: 12200\n",
      "Loss: 0.0285\n",
      "Epoch: 12250\n",
      "Loss: 0.0283\n",
      "Epoch: 12300\n",
      "Loss: 0.0283\n",
      "Epoch: 12350\n",
      "Loss: 0.0282\n",
      "Epoch: 12400\n",
      "Loss: 0.0287\n",
      "Epoch: 12450\n",
      "Loss: 0.0294\n",
      "Epoch: 12500\n",
      "Loss: 0.0256\n",
      "Epoch: 12550\n",
      "Loss: 0.0320\n",
      "Epoch: 12600\n",
      "Loss: 0.0278\n",
      "Epoch: 12650\n",
      "Loss: 0.0276\n",
      "Epoch: 12700\n",
      "Loss: 0.0286\n",
      "Epoch: 12750\n",
      "Loss: 0.0288\n",
      "Epoch: 12800\n",
      "Loss: 0.0273\n",
      "Epoch: 12850\n",
      "Loss: 0.0287\n",
      "Epoch: 12900\n",
      "Loss: 0.0271\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m----> 3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Now we need to add noise to x\u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# x: (B, 1, 28, 28)\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnoise_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_ratio\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgen_noise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Conv to device\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\kktan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:732\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    730\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 732\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    738\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\kktan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:788\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    787\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 788\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    789\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    790\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\kktan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\kktan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\kktan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:146\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    143\u001b[0m img \u001b[38;5;241m=\u001b[39m _Image_fromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    149\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32mc:\\Users\\kktan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\kktan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kktan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\kktan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:1372\u001b[0m, in \u001b[0;36mRandomRotation.forward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m   1369\u001b[0m         fill \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fill]\n\u001b[0;32m   1370\u001b[0m angle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdegrees)\n\u001b[1;32m-> 1372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrotate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mangle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kktan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1132\u001b[0m, in \u001b[0;36mrotate\u001b[1;34m(img, angle, interpolation, expand, center, fill)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;66;03m# due to current incoherence of rotation angle direction between affine and rotate implementations\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;66;03m# we need to set -angle.\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m matrix \u001b[38;5;241m=\u001b[39m _get_inverse_affine_matrix(center_f, \u001b[38;5;241m-\u001b[39mangle, [\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m], \u001b[38;5;241m1.0\u001b[39m, [\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m])\n\u001b[1;32m-> 1132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrotate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kktan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:669\u001b[0m, in \u001b[0;36mrotate\u001b[1;34m(img, matrix, interpolation, expand, fill)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;66;03m# grid will be generated on the same device as theta and img\u001b[39;00m\n\u001b[0;32m    667\u001b[0m grid \u001b[38;5;241m=\u001b[39m _gen_affine_grid(theta, w\u001b[38;5;241m=\u001b[39mw, h\u001b[38;5;241m=\u001b[39mh, ow\u001b[38;5;241m=\u001b[39mow, oh\u001b[38;5;241m=\u001b[39moh)\n\u001b[1;32m--> 669\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_apply_grid_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kktan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:575\u001b[0m, in \u001b[0;36m_apply_grid_transform\u001b[1;34m(img, grid, mode, fill)\u001b[0m\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# 'bilinear'\u001b[39;00m\n\u001b[0;32m    573\u001b[0m         img \u001b[38;5;241m=\u001b[39m img \u001b[38;5;241m*\u001b[39m mask \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m mask) \u001b[38;5;241m*\u001b[39m fill_img\n\u001b[1;32m--> 575\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43m_cast_squeeze_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneed_cast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneed_squeeze\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\kktan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:532\u001b[0m, in \u001b[0;36m_cast_squeeze_out\u001b[1;34m(img, need_cast, need_squeeze, out_dtype)\u001b[0m\n\u001b[0;32m    528\u001b[0m         img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mto(req_dtype)\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img, need_cast, need_squeeze, out_dtype\n\u001b[1;32m--> 532\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cast_squeeze_out\u001b[39m(img: Tensor, need_cast: \u001b[38;5;28mbool\u001b[39m, need_squeeze: \u001b[38;5;28mbool\u001b[39m, out_dtype: torch\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m need_squeeze:\n\u001b[0;32m    534\u001b[0m         img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39msqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k = 0\n",
    "while True:\n",
    "    for x, label in loader:\n",
    "        # Now we need to add noise to x\n",
    "        # x: (B, 1, 28, 28)\n",
    "        noise_x, noise, noise_ratio = gen_noise(x)\n",
    "        \n",
    "        # Conv to device\n",
    "        noise = noise.to(device)\n",
    "        noise_x = noise_x.to(device)\n",
    "        noise_ratio = noise_ratio.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        pred = model(noise_x, label, noise_ratio)\n",
    "        loss = criterion(pred, noise)\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        ema_model.step(model)\n",
    "        \n",
    "        k += 1\n",
    "        if k % 50 == 0:\n",
    "            print(f\"Epoch: {k}\\nLoss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65bfb0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample(model, target_labels, steps=1000, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    B = len(target_labels)\n",
    "    labels = torch.tensor(target_labels).to(device)\n",
    "    \n",
    "    # 1noise\n",
    "    x = torch.randn((B, 1, 32, 32)).to(device)\n",
    "    \n",
    "    t_list = torch.linspace(1, 0, steps + 1)\n",
    "    \n",
    "    for i in range(steps):\n",
    "        curr_t = t_list[i]\n",
    "        next_t = t_list[i+1]\n",
    "        \n",
    "        t_batch = torch.full((B,), curr_t).to(device)\n",
    "        \n",
    "        # predict noise\n",
    "        pred_noise = model(x, labels, t_batch)\n",
    "        \n",
    "        # Take steps in general direction\n",
    "        sqrt_t = torch.sqrt(curr_t)\n",
    "        sqrt_one_minus_t = torch.sqrt(1 - curr_t)\n",
    "        \n",
    "        # Avoid division by zero at the very end\n",
    "        pred_x0 = (x - sqrt_t * pred_noise) / (sqrt_one_minus_t + 1e-8)\n",
    "        pred_x0 = torch.clamp(pred_x0, -1, 1)\n",
    "        \n",
    "        # Step in state\n",
    "        if next_t > 0:\n",
    "            sqrt_next_t = torch.sqrt(next_t)\n",
    "            sqrt_one_minus_next_t = torch.sqrt(1 - next_t)\n",
    "            x = sqrt_one_minus_next_t * pred_x0 + sqrt_next_t * pred_noise\n",
    "        else:\n",
    "            x = pred_x0 # The final step is just the clean image\n",
    "            \n",
    "    model.train()\n",
    "    \n",
    "    # Convert back to [0, 1] for viewing\n",
    "    return (x + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1800fc37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x200 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot my shi\n",
    "digits_to_gen = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "generated_images = sample(ema_model.ema_model, digits_to_gen, steps=8, device=device)\n",
    "\n",
    "fig, axes = plt.subplots(1, 10, figsize=(15, 2))\n",
    "for i in range(10):\n",
    "    axes[i].imshow(generated_images[i].cpu().squeeze(), cmap='gray')\n",
    "    axes[i].set_title(f\"Label: {i}\")\n",
    "    axes[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5e5ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
